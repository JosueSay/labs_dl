{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971fb2c8",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Hyperparamter Tunning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c114f5",
   "metadata": {},
   "source": [
    "## Integrantes\n",
    "\n",
    "- Josué Say\n",
    "- Andre Jo\n",
    "\n",
    "## Repositorio\n",
    "\n",
    "- [Enlace a GitHub](https://github.com/JosueSay/labs_dl/tree/main/lab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f62977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f2d6d",
   "metadata": {},
   "source": [
    "## Carga del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b9ed9",
   "metadata": {},
   "source": [
    "### Librerías y constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "BASE_DIR = \"./data/\"\n",
    "BATCH_SIZE = 64\n",
    "os.makedirs(BASE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1859ad",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0de3e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740fd452",
   "metadata": {},
   "source": [
    "El dataset de pytorch obtiene la data en formato PIL (Python Image Library) por lo que debemos pasarlo a tensores y que la red neuronal sea más fácil en procesar y luego transformamos sus datos de imágenes en rango `[0-255]` a `[0-1]`, esto sería una transformación base porque debemos al transformar datos debemos de actualizar la distribución y eso lo hacemos sabiendo la `mean` y `std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc23b3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size dataset train 60000\n",
      "Size dataset test 10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root=BASE_DIR, train=True, download=True, transform=base_transform)\n",
    "test_data = datasets.MNIST(root=BASE_DIR, train=False, download=True, transform=base_transform)\n",
    "\n",
    "print(f\"Size dataset train {len(train_data)}\")\n",
    "print(f\"Size dataset test {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315cd3c",
   "metadata": {},
   "source": [
    "Descargamos la data para train y test en caso que no este en `BASE_DIR` lo descargará sino solo lo leera de la carpeta `data`. Se aplica la transformación base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ddc8c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6acc4",
   "metadata": {},
   "source": [
    "Cargamos los datos para aplicar una transformación para la carga de datos aplicando el BATCH_SIZE dicho y si la data se queire revolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9519bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.1307\n",
      "Std: 0.3080\n"
     ]
    }
   ],
   "source": [
    "mean = 0.0\n",
    "std = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "for images, _ in train_loader:\n",
    "    batch_mean = images.mean()\n",
    "    batch_std = images.std()\n",
    "    \n",
    "    mean += batch_mean\n",
    "    std += batch_std\n",
    "    num_batches += 1\n",
    "\n",
    "mean /= num_batches\n",
    "std /= num_batches\n",
    "\n",
    "print(f\"Mean: {mean.item():.4f}\")\n",
    "print(f\"Std: {std.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d5005",
   "metadata": {},
   "source": [
    "Se obtiene los valores exactos para usarlos en la transformación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce598baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root=BASE_DIR, train=True, download=False, transform=final_transform)\n",
    "test_data = datasets.MNIST(root=BASE_DIR, train=False, download=False, transform=final_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b4040",
   "metadata": {},
   "source": [
    "Dado la `mean` y `std` ya es posible hacer la preparación de la data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c082f",
   "metadata": {},
   "source": [
    "## Construcción del Modelo MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2072a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48dd33a5",
   "metadata": {},
   "source": [
    "## Experimentación con Distintas Configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882552b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bdac957",
   "metadata": {},
   "source": [
    "## Tuning de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719163ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0bc1b12",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81b38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afe55ff9",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- [Datasets PyTorch](https://docs.pytorch.org/vision/stable/datasets.html#mnist)\n",
    "- [MNIST PyTorch](https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html?highlight=mnist#torchvision.datasets.MNIST)\n",
    "- [Transforming PyTorch](https://docs.pytorch.org/vision/stable/transforms.html#)\n",
    "- [DataLoader PyTorch](https://docs.pytorch.org/docs/stable/data.html#)\n",
    "- [Compose PyTorch](https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Compose.html#torchvision.transforms.v2.Compose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
