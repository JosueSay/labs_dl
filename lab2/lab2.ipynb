{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971fb2c8",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Hyperparamter Tunning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c114f5",
   "metadata": {},
   "source": [
    "## Integrantes\n",
    "\n",
    "- Josué Say\n",
    "- Andre Jo\n",
    "\n",
    "## Repositorio\n",
    "\n",
    "- [Enlace a GitHub](https://github.com/JosueSay/labs_dl/tree/main/lab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3f62977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f2d6d",
   "metadata": {},
   "source": [
    "## Carga del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b9ed9",
   "metadata": {},
   "source": [
    "### Librerías y constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96a8a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "BASE_DIR = \"./data/\"\n",
    "BATCH_SIZE = 64\n",
    "FACTOR_VALIDATION_SET = 0.9\n",
    "os.makedirs(BASE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1859ad",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "347f6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParamsTransform(bs):\n",
    "    \n",
    "    # El dataset de pytorch obtiene la data en formato PIL (Python Image Library) por lo que debemos pasarlo a \n",
    "    # tensores y que la red neuronal sea más fácil en procesar y luego transformamos sus datos de imágenes en rango \n",
    "    # `[0-255]` a `[0-1]`, esto sería una transformación base porque debemos al transformar datos debemos de actualizar \n",
    "    # la distribución y eso lo hacemos sabiendo la `mean` y `std`.\n",
    "    base_transform = v2.Compose([\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True)\n",
    "    ])\n",
    "     \n",
    "    # Descargamos la data para train y test en caso que no este en `BASE_DIR` lo descargará sino solo lo leera de la carpeta `data`. Se aplica la transformación base.\n",
    "    train_data = datasets.MNIST(root=BASE_DIR, train=True, download=True, transform=base_transform)\n",
    "    \n",
    "    # Cargamos los datos para aplicar una transformación para la carga de datos aplicando el batch_size (bs) dicho y si la data se queire revolver.\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=bs, shuffle=True)\n",
    "    \n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    # Se obtiene los valores exactos para usarlos en la transformación final\n",
    "    for images, _ in train_loader:\n",
    "        batch_mean = images.mean()\n",
    "        batch_std = images.std()\n",
    "        \n",
    "        mean += batch_mean\n",
    "        std += batch_std\n",
    "        num_batches += 1\n",
    "\n",
    "    mean /= num_batches\n",
    "    std /= num_batches\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fe993",
   "metadata": {},
   "source": [
    "### Proceso de carga final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce598baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size dataset train 60000\n",
      "Size dataset test 10000\n"
     ]
    }
   ],
   "source": [
    "mean, std = getParamsTransform(bs=BATCH_SIZE)\n",
    "\n",
    "final_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root=BASE_DIR, train=True, download=False, transform=final_transform)\n",
    "test_data = datasets.MNIST(root=BASE_DIR, train=False, download=False, transform=final_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Size dataset train {len(train_data)}\")\n",
    "print(f\"Size dataset test {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b4040",
   "metadata": {},
   "source": [
    "Dado la `mean` y `std` ya es posible hacer la preparación de la data y se puede hacer el dataset para `validation`, por ejemplo 90% para entrenamiento y 10% para validación del dataset de train el cual es el que contiene más datos. Pero, puede editarse la proporción para el los datos de validation editanto `FACTOR_VALIDATION_SET`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cffaf7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(FACTOR_VALIDATION_SET * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "\n",
    "train_set, val_set = random_split(train_data, [train_size, val_size])\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73066b8d",
   "metadata": {},
   "source": [
    "Al separar la data ya podemos utilizar los sets `train_loader`, `val_loader` y `test_loader`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c082f",
   "metadata": {},
   "source": [
    "## Construcción del Modelo MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b243a",
   "metadata": {},
   "source": [
    "- 784 entradas (una por cada píxel de la imagen de 28x28).\n",
    "- 10 salidas (una por cada clase del dígito del 0 al 9). En este caso, la neurona de salida con el valor de función de activación más alto representa la clase que el modelo está pronósticando. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89031954",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03214964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a26765",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3a2072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb2a8b",
   "metadata": {},
   "source": [
    "- `nn.Flatten()`: Convierte la imagen 2D de `28x28` en un vector de `784` elementos.\n",
    "- `nn.Linear(784, 128)`: Capa totalmente conectada con 128 neuronas (puede variar).\n",
    "- `nn.ReLU()`: Activación no lineal común para MLP.\n",
    "- `nn.Linear(128, 10)`: Capa final con 10 salidas (una por cada dígito)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd33a5",
   "metadata": {},
   "source": [
    "## Experimentación con Distintas Configuraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4817d",
   "metadata": {},
   "source": [
    "### Librerías y constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89567c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "models = {}\n",
    "mlp_instances = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33bfadf",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25b24de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPConfiguration(nn.Module):\n",
    "    def __init__(self, hidden_layers, activation_fn):\n",
    "        \"\"\"\n",
    "        Parámetros:\n",
    "        - hidden_layers (list[int]): número de neuronas por cada capa.\n",
    "        - activation_fn (nn.Module): clase de función de activación a aplicar en cada capa oculta.\n",
    "\n",
    "        Estructura:\n",
    "        - La entrada se aplana con nn.Flatten() ya que MNIST son imágenes 28x28 (784 píxeles).\n",
    "        - Cada capa oculta es una combinación de nn.Linear + activation_fn.\n",
    "        - La capa final es nn.Linear que proyecta al espacio de 10 clases (dígitos 0 a 9).\n",
    "        \"\"\"\n",
    "        super(MLPConfiguration, self).__init__()\n",
    "        layers = [nn.Flatten()]  # Convierte imagen 2D a vector 1D\n",
    "\n",
    "        input_dim = 28 * 28  # Tamaño de la entrada (por defecto para el tensor de imágenes)\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(input_dim, h))     # Conectar capas\n",
    "            layers.append(activation_fn())             # Activación no lineal\n",
    "            input_dim = h                              # Actualiza el tamaño para la siguiente capa\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, 10))  # Capa de salida con (10 clases para los números)\n",
    "        self.model = nn.Sequential(*layers)      # Juntar todas las capas\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4627ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1\n",
    "models[\"mlp_1_simple\"] = {\n",
    "    \"hidden_layers\": [128],\n",
    "    \"activation_fn\": nn.ReLU,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 10\n",
    "}\n",
    "\n",
    "# Modelo 2\n",
    "models[\"mlp_2_deep\"] = {\n",
    "    \"hidden_layers\": [256, 128],\n",
    "    \"activation_fn\": nn.Tanh,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 20\n",
    "}\n",
    "\n",
    "# Modelo 3\n",
    "models[\"mlp_3_wide\"] = {\n",
    "    \"hidden_layers\": [512, 256],\n",
    "    \"activation_fn\": nn.LeakyReLU,\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 15\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3456a2d",
   "metadata": {},
   "source": [
    "### Hiperparámetros utilizados\n",
    "\n",
    "- `hidden_layers`: lista que indica cuántas capas ocultas tiene el modelo y cuántas neuronas contiene cada una.\n",
    "- `activation_fn`: función de activación que se aplicará después de cada capa oculta.\n",
    "- `learning_rate`: tasa de aprendizaje usada para actualizar los pesos durante el entrenamiento.\n",
    "- `batch_size`: número de ejemplos procesados antes de actualizar los parámetros.\n",
    "- `epochs`: número total de recorridos completos sobre el conjunto de entrenamiento.\n",
    "\n",
    "#### Modelo 1\n",
    "\n",
    "- Tiene una sola capa con 128 neuronas, lo que le permite aprender patrones simples y generales del conjunto de imágenes.\n",
    "- Se utiliza `ReLU` como función de activación.\n",
    "- Un `learning_rate` de 0.01 permite actualizaciones rápidas.\n",
    "- `batch_size` de 64.\n",
    "- Entrena durante 10 épocas.\n",
    "\n",
    "#### Modelo 2\n",
    "\n",
    "- Tiene dos capas permite al modelo componer más relacioiens con la imagen de entrada.\n",
    "- La función `Tanh` comprime las salidas entre -1 y 1.\n",
    "- Una tasa de aprendizaje más pequeña (`0.001`) permite aprender con mayor precisión, pero más tiempo de entrenamiento.\n",
    "- El `batch_size` de 128 reduce la varianza de las actualizaciones.\n",
    "- El número de épocas se incrementa a 20 para mayor capacidad de entrenamiento.\n",
    "\n",
    "#### Modelo 3\n",
    "\n",
    "- Posee dos capas con más neuronas.\n",
    "- `LeakyReLU` es una variante de `ReLU` que evita que las neuronas “mueran” (salida siempre 0), permitiendo mantener información incluso con entradas negativas.\n",
    "- El `learning_rate` bajo ayuda a que el modelo ajuste los pesos.\n",
    "- Al tener un `batch_size` pequeño (32), el modelo actualiza sus pesos más frecuentemente con datos más variados.\n",
    "- Entrena por 15 épocas.\n",
    "\n",
    "\n",
    "#### Comparación general\n",
    "\n",
    "| Modelo         | Capas ocultas | Activación | Learning Rate | Batch Size | Epochs |\n",
    "| -------------- | ------------- | ---------- | ------------- | ---------- | ------ |\n",
    "| 1              | \\[128]        | ReLU       | 0.01          | 64         | 10     |\n",
    "| 2              | \\[256, 128]   | Tanh       | 0.001         | 128        | 20     |\n",
    "| 3              | \\[512, 256]   | LeakyReLU  | 0.0005        | 32         | 15     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b079a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, config in models.items():\n",
    "    model = MLPConfiguration(hidden_layers=config[\"hidden_layers\"],\n",
    "                activation_fn=config[\"activation_fn\"])\n",
    "    mlp_instances[name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdac957",
   "metadata": {},
   "source": [
    "## Tuning de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719163ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0bc1b12",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81b38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afe55ff9",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- [Datasets PyTorch](https://docs.pytorch.org/vision/stable/datasets.html#mnist)\n",
    "- [MNIST PyTorch](https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html?highlight=mnist#torchvision.datasets.MNIST)\n",
    "- [Transforming PyTorch](https://docs.pytorch.org/vision/stable/transforms.html#)\n",
    "- [DataLoader PyTorch](https://docs.pytorch.org/docs/stable/data.html#)\n",
    "- [Compose PyTorch](https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.v2.Compose.html#torchvision.transforms.v2.Compose)\n",
    "- [Torch.nn PyTorch](https://docs.pytorch.org/docs/stable/nn.html)\n",
    "- [MLP PyTorch](https://docs.pytorch.org/vision/main/generated/torchvision.ops.MLP.html)\n",
    "- [Sequential PyTorch](https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
